# Sensitivity analysis for mediation analysis

```{r}
#| include: false
library(here)
library(DiagrammeR)
library(tidyverse)
library(CMAverse)
```

::: callout-note
## Learning outcomes

-   Suggest relevant sensitivity analyses for mediation analyses
-   Perform sensitivity analysis for unmeasured confounding
:::

Unmeasured or uncontrolled confounding is a common problem in
observational studies. This is a challenge to observational research
even in the analysis of total effects.

When we are interested in direct and indirect effects, the assumptions
about confounding that are needed to identify these effects are even
stronger than for total effects.

We might be worried that these assumptions are violated and that our
estimates are biased.

Sensitivity analysis techniques can help assess HOW ROBUST results are
to violations in the assumptions being made.

These techniques assess the extent to which an unmeasured variable (or
variables) would have to affect both the exposure and the outcome in
order for the observed associations between the two to be attributable
solely to confounding rather than a causal effect of the exposure on the
outcome.

It can also be useful in assessing a plausible range of values for the
causal effect of the exposure on the outcome corresponding to a
plausible range of assumptions concerning the relationship between the
unmeasured confounder and the exposure and outcome.

## Sensitivity analysis for unmeasured confounding for total effects

Consider the following figure in which *U* represents an unmeasured
confounder, *C* measured covariables, *A* the exposure and *Y* the
outcome.

```{r}
#| echo: false

# Creating The causal diagram for a mediation model
library(DiagrammeR)
grViz("
digraph {
  graph []
  node [shape = plaintext]
    C [label = 'C']
    A [label = 'A']
    Y [label = 'Y']
    U [label = 'U']
  edge [minlen = 2]
    A->Y
    C->A
    C->Y
    U->A
    U->Y
{rank = same; C; A; Y; }
{rank = max; U ; }
}
")
```

The basic idea of sensitivity analysis is to specify parameters
corresponding to the relationships between *U* and *Y* and between *U*
and *A* and from these, along with the observed data, to obtain
"corrected" effect estimates corresponding to what would have been
obtained had control been made for *U* and not only *C*.

The results essentially compare:

What we obtain adjusting only for measured covariables *C* with what we
would have obtained had it been possible to adjust for measured
covariables *C* and unmeasured covariable(s) *U*.

If it is thought that adjusting for *C* and *U* together would suffice
to control for confounding, then we may also interpret the results as
comparing the effect estimate that is obtained adjusting only for
measured covariables *C* versus the true causal effect.

### Continuous outcomes

Suppose then we have obtained an estimate of the effect of the exposure
*A* on the outcome *Y* conditional on measured covariables *C* using
regression analysis.

We will define the bias factor **B_add(*c*)** on the additive scale as
the difference between the expected differences in outcomes comparing
*A* = *a* and *A* = *a*^\*^ conditional on covariables *C* = *c* and
what we would have obtained had we been able to adjust for *U* as well.

If the exposure is binary, then we simply have *a* = 1 and *a*^\*^ = 0.

A simple approach to sensitivity analysis is possible if we assume that
**(A8.1.1)** *U* is binary and **(A8.1.2)** that the effect of *U* (on
the additive scale) is the same for those with exposure level *A* = *a*
and exposure level *A* = *a*^\*^ (no *U* × *A* interaction).

If these assumptions hold, let γ be the effect of *U* on *Y* conditional
on *A* and *C*, that is:

$γ = E(Y|a,c,U = 1)$ − $E(Y|a,c,U = 0)$

Note that by assumption **(A8.1.2)**,

$γ = E(Y|a,c,U = 1)$ − $E(Y|a,c,U = 0)$

is the same for both levels of the exposure of interest.

Note also that *γ* is the effect of *U* on *Y* already having adjusted
for *C*; that is, in some sense the effect of *U* on *Y* not through *C*

Now let *δ* denote the difference in the prevalence of the unmeasured
confounder *U* for those with *A*=*a* versus those with *A* = *a*^\*^,
that is:

$δ = P(U = 1|a,c)$ − $P(U = 1|a^*,c)$

Under assumptions **(A8.1.1)** and **(A8.2.2)**, the bias factor is
simply given by the product of these two sensitivity analysis
parameters:

$B_add(c) = γδ$

Thus to calculate the bias factor we only need to specify the effect of
*U* on *Y* and the prevalence difference of *U* between the two exposure
groups and then take the product of these two parameters.

Once we have calculated the bias term **B_add(c)**, we can simply
estimate our causal effect conditional on *C* and then subtract the bias
factor to get the "corrected estimate" - that is, what we would have
obtained if we had controlled for *C* and *U*.

Under these simplifying assumptions **(A8.1.1)** and **(A8.1.2)**, we
can also get adjusted confidence intervals by simply subtracting *γδ*
from both limits of the estimated confidence intervals.

We may not believe any particular specification of the parameters *γ*
and *δ*, but we could vary these parameters (based on expert knowledge
or previous reported estimates of the associations of the *C* and *Y*)
over a range of plausible values to obtain what were thought to be a
plausible range of corrected estimates.

Using this technique, we could also examine how substantial the
confounding would have to be to explain away an effect (we could do this
for the estimate and confidence interval).

### Continuous outcome with different sensitivity analysis parameters for different covariable values

Suppose now that instead of focusing on effects conditional on a
particular covariate value *C* = *c* or specifying the sensitivity
analysis parameters *γ* and *δ* to be the same for each covariable *C*,
we were interested in the overall marginal effect averaged over the
covariables and we wanted to specify different sensitivity analysis
parameters for different covariable levels.

Suppose then for each level of the covariates of interest *C* = *c* we
specified a value for the effect of *U* on *Y*

$γ(c) = E(Y|a, c,U = 1) − E(Y|a, c,U = 0)$

and also a value for the prevalence difference of *U* between those with
exposure status *A* = *a* and *A* = *a*^\*^ and covariables *C* = *c*

$δ(c) = P(U = 1|a, c)−P(U = 1|a^*, c)$

We could then obtain an overall bias factor, **Badd**, by taking the
product of the bias factors in each strata of *C* and then averaging
these over *C*, weighting each strata of *C* according to what
proportion of the sample was in that strata. The overall bias factor is
then

$Badd=\sum~c~\{γ(c)δ(c)\}P(C=c)$

We could then subtract this overall bias factor from our estimate
adjusted only for *C* to obtain a corrected estimate.

In this case, however, we can no longer simply subtract the bias factor
from both limits of the confidence intervals because this does not take
into account the variability in our estimates of the proportion of the
sample in each strata of the covariates *P(C = c*).

Corrected confidence intervals could instead be obtained by
bootstrapping.

We first load the nhanes data:

```{r}
# first load the dataset
nhanes <- read.csv(here::here("data/nhanes_dataset.csv"))

nhanes <- nhanes %>%
  select(
    id = seqn,
    w1 = age,
    w2 = gender,
    w3 = education_clean,
    w4 = smoke, 
    a = total_redmeat,            #this is the exposure
    m = magic_biomarker,          #this is the mediator
    y = blood_glucose) %>%        #this is the outcome
    na.omit()
```

We then run the same example as before with red meat, inflammation and
blood glucose.

```{r}
res_rb_confounders <- cmest(
  data = nhanes, model = "rb", outcome = "y", exposure = "a",
  mediator = "m", basec = c("w1", "w2", "w3"), EMint = TRUE,
  mreg = list("linear"), yreg = "linear",
  astar = 0, a = 1, mval = list(2.5),
  estimation = "paramfunc", inference = "delta"
)

summary(res_rb_confounders)
```

To perform sensitivity analysis for unmeasured confounding we simply add
another line of code.

```{r}
uc_sens <- cmsens(
  object = res_rb_confounders,
  sens = "uc"
)

uc_sens

```
