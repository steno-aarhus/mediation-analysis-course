[
  {
    "objectID": "sessions/motivation-for-mediation-analysis.html",
    "href": "sessions/motivation-for-mediation-analysis.html",
    "title": "2  Motivation for mediation analysis",
    "section": "",
    "text": "Basic, clinical and epidemiological research are often interested in whether a specific intervention has an effect on a disease. Once that has been established, the natural subsequent question is why the intervention had an effect? What was the mechanism? (1).\nMediation analysis can, if used correctly, answer such questions. However, this is unfortunately rarely the case because the methods are used incorrectly. A recent systematic review of the reporting quality of studies applying mediation analysis showed that most of the studies had incomplete reporting (2). This impacts both reproducibility and translation into practice.\nAlongside the applied research, the methodological framework for conducting mediation analysis has also evolved rapidly in recent years. Unfortunately, most applied examples have not caught up with this progression in methodology. In fact, a scoping review found that between 2015 to 2019 only 29.3% of studies using mediation analysis used modern mediation analysis methods (3).\n\nshow example of mediation analysis\ndiscussion on motivations for mediation analysis\nrelevance for basic, clinical and epidemiological research\ndiscussion with participants - exercise below\n\n\n\n\n\n\n\n\nExercise: Understanding different study designs (30 min)\n\n\n\nYou will now be placed in different groups and read selected sections of different mediation analyses within different study designs. You have 15 min to complete the task. Then, each group will briefly present their paper, the approach used and what they thought about it.\n\n2.0.1 Group 1: Intervention study a\nPaper: Shoer et al. 2023\n\nread the abstract\nread section ‘Mediation analysis’ under ‘Methods’\nread section ‘The microbiome mediates the diet’s effect’ under ‘Results’\ntry to understand Fig. 4.\n\nTask: explain the overall study and the mediation analysis. What does the results imply?\n\n\n2.0.2 Group 2: Intervention study b\nPaper: Johansen et al. 2020\n\nread the abstract\nread from “Single mediation analysis” under ‘Statistical analysis’\ntry to understand table 4\nread from “To explore the role of weight loss in relation to beta cell function we performed single mediation analysis” under ‘Discussion’\n\nTask: explain the overall study and the mediation analysis. What does the results imply? How did the authors interpret the results? How do you interpret the results?\n\n\n2.0.3 Group 3: Cohort study\nPaper: Wang et al. 2022\n\nread the abstract\nread from “To test whether an association between the metabolite profile score and risk of type 2 diabetes…” under ‘Statistical analysis’\ntry to understand Fig. 4\nread the conclusion\n\nTask: explain the overall study and the mediation analysis. What does the results imply? How did the authors interpret the results? How do you interpret the results?\n\n\n2.0.4 Group 4: Cross-sectional study\nPaper: Shi et al. 2022\n\nread the abstract\nthey used a specific algorithm to identify mediation. You do not have to understand how it works. Simply note whether they adjusted for specific variables in their analysis (Hint: look in the methods section)\nRead section ‘Mediation by the gut microbial species Dialister invisus’ under ‘Results’\n\nTask: explain the overall study design, what exposure, mediator and outcomes were they interested in? Are their results causal?\n\n\n\n\n3 References\n\n\n\n\n1. VanderWeele TJ. Mediation Analysis: A Practitioner’s Guide. Annual Review of Public Health [Internet] 2016 [cited 2022 Aug 17];37:17–32. Available from: https://doi.org/10.1146/annurev-publhealth-032315-021402\n\n\n2. Rrn R, Ag C, Mk B, Sm G, H L, Jh M. A Systematic Review of the Reporting Quality of Observational Studies That Use Mediation Analyses. Prevention science : the official journal of the Society for Prevention Research [Internet] 2022 [cited 2023 Sep 27];23. Available from: https://pubmed.ncbi.nlm.nih.gov/35167030/\n\n\n3. Rijnhart JJM, Lamp SJ, Valente MJ, MacKinnon DP, Twisk JWR, Heymans MW. Mediation analysis methods used in observational research: A scoping review and recommendations. BMC Medical Research Methodology [Internet] 2021 [cited 2023 Sep 27];21:1–17. Available from: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01426-3"
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html",
    "href": "sessions/causal-mediation-analysis-introduction.html",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "",
    "text": "5 Study designs for causal mediation analysis\nMediation analysis can be used in both intervention and observational studies.\nA key assumption is that the exposure should be before the mediator and the mediator and exposure before the outcome. It is possible by design to have these three variables measured at different time points. In practice, this is rarely the case. Probably because the study was not designed to conduct mediation analysis."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#what-is-a-cause",
    "href": "sessions/causal-mediation-analysis-introduction.html#what-is-a-cause",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n4.1 What is a cause?",
    "text": "4.1 What is a cause?\nIn a way this can be very intuitive. If I press the switch, the light will come on. We use causal reasoning all the time. If I do A, then Y will happen. Some relationships we can define them to be deterministic. Doing A will always lead to Y. This is useful for our intuition but when we work with health outcomes it is more complicated.\n\n\n\n\n\n\nNotation\n\n\n\nA = received treatment/intervention/exposure (e.g., 1 = intervention, 0 = no intervention)\nY = observed outcome (e.g., 1 = developed the outcome, 0 = no outcome)\n\\(Y^{a=1}\\) = Counterfactual outcome under treatment a (i.e., the outcome had everyone, counter to the fact, recieved treatment a = 1)\n\\(Y^{a=0}\\) = Counterfactual outcome under treatment a (i.e., the outcome had everyone, counter to the fact, recieved treatment a = 0)\n\n\n\n4.1.1 Individual causal effect\nWhen investigating health outcomes, we would ideally want to know if you do X, then Y will happen. We could have a specific question:\n\nWill eating more red meat give me higher blood glucose in 1 year?\n\nTo answer this question we would ideally have you consume more red meat over 1 year and measure your blood glucose levels. Then, we would turn back time, and make you eat something else over 1 year and then measure your blood glucose levels again. If there is a difference between your two outcomes, then we say there is a causal effect.\nBut we can never do this in the real world.\n\n4.1.2 Average causal effect\nInstead, we can perform a randomized controlled trial. We now ask a slightly different question:\n\nWill eating more red meat give adults higher blood glucose in 1 year?\n\nWe can randomely assigning one group to consume more red meat and the other group to consume more of something else over 1 year. Then we compare the average blood glucose levels after 1 year in each of the groups. If there is a difference, we could say there is an average causal effect.\n\n\n\n\n\n\nNotation\n\n\n\nWe now modify the terms a little.\n\\(E[Y^{a=1}]\\) the average counterfactual outcome, had all subjects in the population received treatment a = 1.\n\\(Pr[Y^{a=1}]\\) the proportion of subjects that would have developed the outcome Y had all subjects in the population of interest received treatment a = 1.\n\n\n\n4.1.3 Definition of a causal effect\nMore formally we can now define a causal effect (ref:Hernan2004):\n\\(E[Y^{a=1} = 1] - E[Y^{a=0} = 1] \\ne 0\\)\n\n4.1.4 Code example: estimating causal effect\nTo get an idea of what is going on, we will simulate a simple dataset with an outcome Y, treatment A and a confounder W.\n\nn &lt;- 1e6\nw &lt;- rnorm(n)\na &lt;- rbinom(n, 1, 0.5)\ny &lt;- rnorm(n, w + a)\n\nThen, we will run a linear regression model for the effect of the treatment on the outcome, adjusting for confounder w.\n\nlm_y &lt;- lm(y ~ a + w)\n\nWe now use this model to predict the outcome, if all had received treatment = 1 and another prediction of the outcome had everyone not received treatment (A = 0).\n\npred_y1 &lt;- predict(lm_y, newdata = data.frame(a = 1, w = w))\npred_y0 &lt;- predict(lm_y, newdata = data.frame(a = 0, w = w))\n\nWe can now get the causal effect, which is the average of the difference in the treatment effect in each group. Or put more formally E[Y^{a=1} = 1] - E[Y^{a=0} = 1]\n\nmean(pred_y1 - pred_y0)\n\n#&gt; [1] 1.004496\n\n\nIt turns out that this average causal effect is the same as the regression coefficient in the linear model.\n\nsummary(lm_y)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ a + w)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -5.1811 -0.6752  0.0012  0.6740  4.6204 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -0.001785   0.001414  -1.263    0.207    \n#&gt; a            1.004496   0.002001 502.095   &lt;2e-16 ***\n#&gt; w            1.000345   0.001001 999.442   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1 on 999997 degrees of freedom\n#&gt; Multiple R-squared:  0.5558, Adjusted R-squared:  0.5558 \n#&gt; F-statistic: 6.256e+05 on 2 and 999997 DF,  p-value: &lt; 2.2e-16\n\n\nA regression-based approach can in some situations also be used. However, for more complicated situations, the regression-based approach fail. The causal intuition in the regression-based approach is also less clear.\n\n\n\n\n\n\nQuestion\n\n\n\nWhy is there no difference between the linear regression coefficient and the predicted mean difference?"
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#association-vs-causation",
    "href": "sessions/causal-mediation-analysis-introduction.html#association-vs-causation",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n4.2 Association vs causation",
    "text": "4.2 Association vs causation\nWhat makes it complicated to estimate a causal effect is that we cannot observe the outcome under different treatments.\nWhen we only have a subset of the outcomes, we have an association. This is illustrated in Fig. 1.\nIf we want to infer a causal effect (i.e., what would have happened, had everyone done A=1 vs A=0), we need three assumptions to be fulfilled:\n\nExchangeability\nConsistency\nPositivity\n\n\n4.2.1 Exchangeability\nThe risk of the outcome in A = 1 would have been the same as the risk of the outcome in A = 0, had those in A = 1 received A = 0.\nThink about a randomized trial where you, by mistake, give the intervention to the other group. The effect should be the same as the one you would have observed had the groups been correct.\nWe can also have conditional exchangeability. The risk is similar in subsets of the population. That could be within the levels of a variable W (e.g., education).\n\n4.2.2 Consistency\nThe treatments under comparison are well-defined and correspond to the versions of treatment observed in the data:\n\nPrecise definition of \\(Y^a\\) via a\nLink counterfactual outcomes with observed outcomes\n\n\\(Y^a = Y\\) for every individual with A = a.\nThe observed outcome for all treated equals the outcome if they had received the treatment.\n\n4.2.3 Positivity\nThe probability of receiving every value of treatment conditional on L is greater than zero. In other words, there must be a probability of being assigned to each treatment level.\nThink, if we don’t have anyone with A = 0 among those with L=1 (e.g. long education), then we cannot estimate the conditional probability of the outcome."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#a-randomized-controlled-trial",
    "href": "sessions/causal-mediation-analysis-introduction.html#a-randomized-controlled-trial",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n4.3 A randomized controlled trial",
    "text": "4.3 A randomized controlled trial\nIn a randomized controlled trial these assumptions are often fulfilled given that the randomization is successful (i.e., have exchangeability and large enough groups), the treatment is clearly defined (consistency) and by design all have the possibility to be in either group (positivity).\nThese assumptions are much harder, let alone impossible, to verify in an observational study. That is why causation is more challenging in observational studies."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#importance-of-good-research-questions",
    "href": "sessions/causal-mediation-analysis-introduction.html#importance-of-good-research-questions",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n4.4 Importance of good research questions",
    "text": "4.4 Importance of good research questions\nWhen we talk about causal effects, we often ask “what if”-questions and we can think of them in the context of a randomized controlled trial.\nA formal extension of this notion is the target trial framework. Here, one first specify the target trial, or referred to as the hypothetical interventions that one would have wanted to perform, to address a specific research question."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#directed-acyclic-graphs",
    "href": "sessions/causal-mediation-analysis-introduction.html#directed-acyclic-graphs",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n4.5 Directed Acyclic Graphs",
    "text": "4.5 Directed Acyclic Graphs\nAnother method to graphically display your research question and your assumptions about your data is by using directed acyclic graphs (DAGs). DAGs are a simple and transparent way to identify and illustrate your assumptions about the causal relationships between variables in your dataset.\nA DAG contains nodes and arrows. It cannot be circular. Fig. 2 shows the different types of variables in a DAG and rules for paths (ref:Tennant2021)."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#causal-mediation-analysis",
    "href": "sessions/causal-mediation-analysis-introduction.html#causal-mediation-analysis",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n4.6 Causal mediation analysis",
    "text": "4.6 Causal mediation analysis\nCausal mediation analyses help you establish whether treatment causes the outcome because it causes the mediator. To do this, causal mediation seek to understand how the paths behave under circumstances different from the observed circumstances (e.g., interventions).\nCausal mediation analysis is an extension of the traditional approach by: - outlining all confounding assumptions needed - handling non-linearity and interaction - clearly defining estimands of interest"
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#confounding-assumptions",
    "href": "sessions/causal-mediation-analysis-introduction.html#confounding-assumptions",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n4.7 Confounding assumptions",
    "text": "4.7 Confounding assumptions\nBy using DAGs, the assumptions about confounding are made much more explicit.\n\n\n\n\nFig. 3. DAG under no intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\nIn Fig 3. we can see that we not only have to take confounding between the treatment and outcome into account, but we also have to take mediator-outcome (\\(A \\leftarrow W \\rightarrow Y\\)) confounding into account.\n\n\n\n\n\n\nRandomized controlled trials\n\n\n\nNote, even if you have a randomized controlled trial, you can have mediator-outcome confounding. This is because the mediator has not been randomized.\nConsequently, mediation analysis in randomized controlled trials also need to do adjustment of potential confounders and residual confounding cannot be ruled out.\n\n\nIn addition, we can have a more complicated situation where the treatment also impacts another mediator that is also a mediator-outcome confounder. This is illustrated in Fig. 4.\n\n\n\n\nFig. 4. DAG under intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\nFrom the DAG rules, we have a special problem that we cannot solve with traditional regression approaches. If we adjust for Z we open the backdoor path from \\(Z \\leftarrow W \\rightarrow Y\\). We will work on how to solve this problem later in the course."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#non-linearity-and-interactions",
    "href": "sessions/causal-mediation-analysis-introduction.html#non-linearity-and-interactions",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n4.8 Non-linearity and interactions",
    "text": "4.8 Non-linearity and interactions\nNeither the product method nor the difference method can take interaction and non-linearity into account.\nCausal mediation analysis can take this into account. It can do this using a regression-based approach. It can also use other causal inference analysis methods such as g-computation, that are different from the traditional regression approach in that:\n\nit builds a causal model. This model can include non-linearity and interactions\nthen artificially manipulate the data to set the treatment and the mediator to certain values\nthen predict the outcome using the causal model and contrast the outcomes\n\nAdditional approaches also exists, but we will not focus on these in this course."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#defining-estimands",
    "href": "sessions/causal-mediation-analysis-introduction.html#defining-estimands",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n4.9 Defining estimands",
    "text": "4.9 Defining estimands\nImagine we have a hypothetical randomized controlled trial where we give participants treatment or no treatment on a specific outcome Y.\n\n\\(Y^{a=1} - Y^{a=0}\\)\n\nFor mediation, we are also interested in the effect of a mediator on this pathway. Now image that we also intervene on the mediator in a new hypothetical randomized controlled trial.\n\n\\(Y^{m=1} - Y^{m=0}\\)\n\nNow consider if we, in the same trial, could intervene on both because we are interested in whether treatment causes the outcome because it causes the mediator.\n\n\n\n\n\n\nNotation\n\n\n\n\\(Y^a\\) = a subject’s outcome if treatment A were set, possible contrary to fact, to a\n\\(M^a\\) = a subject’s value of the mediator if the exposure A were set to the value of a\n\\(Y^{a,m}\\) = a subject’s outcome if A were set to a and M were set to m\n\\(Y^{a,M_a}\\) = a subject’s outcome if A were set to a and M were set the value m would have had had a been set to a. Note, this is a nested counterfactual\n\n\nWe can now define these estimands:\n\nthe controlled direct effect (CDE)\nnatural direct effect (NDE)\nnatural indirect effect (NIE)\n\n\n4.9.1 Controlled direct effect\nThe effect of A on Y not mediated through M. Fixing the value of M to m.\n\n\\(Y^{a=1,m}\\) - \\(Y^{a=0,m}\\)\n\nWe intervene on \\(a\\) but fix \\(m\\) to a certain value. The CDE is how much the outcome would change on average if the mediator were fixed at level m uniformly in the population but the treatment were changed from 0 to 1.\nThis could be relevant in the context of a change in a policy that impacted the mediator for everyone. For instance, if air pollution was a mediator between physical activity and cardiovascular disease risk. If a new policy would change the level of air pollution for all while we implement an intervention to increase biking in the city.\nThis effect is not used that often. But can be highly relevant in some situations.\n\n4.9.2 (Pure) Natural direct effect\nThe effect that would remain, if we were to disable the pathway from exposure to mediator.\n\n\\(Y^{a=1,M_a=0}\\) - \\(Y^{a=0,M_a=0}\\)\n\nThe PNDE is how much the outcome would change if the exposure was set at a = 1 versus a* = 0 but for each individual the mediator was kept at the level it would have taken, for that individual, in the absence of the exposure.\nNote that the word “natural” refers to the nested counterfactual, the level the mediator would have taken in the absence of exposure. What it would naturally have been in the absence of exposure.\n\n4.9.3 Total natural direct effect\n\n\\(Y^{a=1,M_a=1}\\) - \\(Y^{a=0,M_a=1}\\)\n\nNote, different from above in that the mediator is kept at the level it would have taken in the presence of the exposure.\n\n4.9.4 (Total) Natural indirect effect\nThe effect of the mediator pathway.\n\n\\(Y^{a=1,M_a=1}\\) - \\(Y^{a=1,M_a=0}\\)\n\nThe NIE is how much the outcome would change on average if the exposure were fixed at level a = 1 but the mediator were changed from the level it would take if a* = 0 to the level it would take if a = 1.\nNote that exposure has to have an effect on M otherwise this will be zero.\n\n4.9.5 Pure natural indirect effect\n\n\\(Y^{a=0,M_a=1}\\) - \\(Y^{a=0,M_a=0}\\)\n\nNote, this is different from the TNIE in that the exposure is set to no intervention.\n\n4.9.6 Interaction effects\nReference interaction:\n\n\\(INT_{ref} = PNDE - CDE\\)\n\nMediation interaction:\n\n\\(INT_{med} = TNIE - PNIE\\)\n\n\n4.9.7 Effect decomposition\nUsing the causal inference framework also allow for effect decomposition, even when there are interaction and non-linearity.\nEffect decomposition is important when we want to assess relative contributions such as the proportion mediated and eliminated.\n\nTE = PNDE + TNIE = TNDE + PNIE\n\n\n4.9.8 Proportions\nProportion CDE:\n\n\\(prop^{CDE} = CDE / TE\\)\n\nProportion \\(INT_{ref}\\)\n\n\\(prop^{INT_{ref}} = INT_{ref} / TE\\)\n\nProportion \\(INT_{med}\\)\n\n\\(prop^{INT_{med}} = INT_{med} / TE\\)\n\nProportion pure natural indirect effect:\n\n\\(prop^{PNIE} = PNIE / TE\\)\n\nProportion mediated:\n\n\\(PM = TNIE / TE\\)\n\nProportion attributable to interaction:\n\n\\(INT = (INT_{ref} + INT_{med}) / TE\\)\n\nProportion eliminated:\n\n\\(PE = (INT_{ref} + INT_{med} + PNIE) / TE\\)"
  },
  {
    "objectID": "sessions/causal-mediation-analysis-introduction.html#two-trials",
    "href": "sessions/causal-mediation-analysis-introduction.html#two-trials",
    "title": "\n4  Introduction to causal mediation analysis\n",
    "section": "\n5.1 Two trials",
    "text": "5.1 Two trials\nIt is possible to conduct two randomized controlled trials to investigate mediation (ref:Imai). One approach is the so-called parallel design. Two randomized controlled trials are conducted in parallel. The first investigates the effect of the treatment on the outcome (i.e., total effect). In the second trial we randomize both the treatment and the mediator.\nFor example, one could use transcranial magnetic stimulation (TMS) to investigate if activation of specific brain regions mediate the propensity to accept more unfair monetary offers in a bidding game called the “ultimatum game” (ref: Knoch 2006). First, you conduct an experiment with unfair bidding and acceptance. Then one conducts the same experiment but with manipulation of the mediator, here TMS to activate a certain brain region.\nA key assumption here is consistency. The subjects should not know the receive the extra intervention.\nThere is also a crossover version (ref: Imai). Here, we first randomize the order of the treatment and control, then observe the effect on mediator and outcome. Then we assign the opposite treatment status and to the value of the mediator that was observed in the first period.\nIn addition to consistency there is the assumption of no carry-over effects."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-estimation.html#recap-from-yesterday-part-1",
    "href": "sessions/causal-mediation-analysis-estimation.html#recap-from-yesterday-part-1",
    "title": "\n6  Estimation of effects using causal mediation analysis\n",
    "section": "\n6.1 Recap from yesterday (part 1)",
    "text": "6.1 Recap from yesterday (part 1)\n\ncausal inference in general\ncausal mediation analysis\n(many) different estimands\n\n\n\n\n\nFig. 3. DAG under no intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\n\n\n\n\n\n\nReflection on yesterday\n\n\n\nTake 2 min to reflect on what your main 2 learning points from yesterday were\nThen, we take 3 min where you talk to your neighbor about these.\nLastly, we will take 5 mins to share in plenum."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-estimation.html#regression-based-approach",
    "href": "sessions/causal-mediation-analysis-estimation.html#regression-based-approach",
    "title": "\n6  Estimation of effects using causal mediation analysis\n",
    "section": "\n6.2 Regression-based approach",
    "text": "6.2 Regression-based approach\nGeneral problems with the traditional approach is when we have exposure-mediator interaction and non-linear relationships.\nCounterfactual-based direct and indirect effects can be estimated, provided that the no-confounding assumption hold. To be able to do so, we need a model for the mediator and a model for the outcome.\nModel for the mediator:\n\\(E(M|A = a, W = w) = \\beta_0 + \\beta_1a + \\beta'_2w\\)\nModel for the outcome:\n\\(E(Y|A = a, M = m, W = w) = \\sigma_0 + \\sigma_1a + \\sigma_2m + \\sigma_3am + \\sigma'_4w\\)\nFrom these two regression models we can estimate the CDE, NDE and NIE.\nTo try this out in practice, we load the NHANES dataset, only keep the variables we need for the example, remove missing data and scale the intake of red meat to be per 65 g/day (i.e., 1-unit higher = 65 g/day).\nNote, that for your own data, you may need to take missing data into account in another way.\n\nnhanes &lt;- read.csv(here::here(\"data\", \"nhanes.csv\"))\n\n#only keeping the variables we need for the example and removing missing variables\n\nnhanes &lt;- nhanes %&gt;% select(id = seqn, w1 = age, w2 = gender, w3 = education, a = total_meat, y = plasma_fasting_glucose, m = serum_c_reactive_protein) %&gt;% na.omit() %&gt;% mutate(\n  a = a/65, #scale to per 65 g/day\n  m = log(m) #m is not normal, so we log transform\n)\n\nWe can now run a model for the mediator only adjusting for a single variable. In practice you would adjust for many more variables to satisfy the confounding assumptions.\n\nlm_m &lt;- lm(m ~ a + w1, data = nhanes)\n\nsummary(lm_m)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = m ~ a + w1, data = nhanes)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.5109 -0.3704 -0.1682  0.5183  4.2162 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -1.5171692  0.0280492 -54.090  &lt; 2e-16 ***\n#&gt; a           -0.3714291  0.1174787  -3.162  0.00157 ** \n#&gt; w1           0.0054803  0.0004741  11.559  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.963 on 12350 degrees of freedom\n#&gt; Multiple R-squared:  0.01302,    Adjusted R-squared:  0.01286 \n#&gt; F-statistic: 81.44 on 2 and 12350 DF,  p-value: &lt; 2.2e-16\n\n\nHere, we see that higher red meat intake is associated with lower CRP levels.\nNow, we run the model for the outcome, including an interaction.\n\nlm_y &lt;- lm(y ~ a + m + a:m + w1, data = nhanes)\n\nsummary(lm_y)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ a + m + a:m + w1, data = nhanes)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -85.46 -18.44  -8.12   3.37 460.32 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 87.55782    1.48088  59.126   &lt;2e-16 ***\n#&gt; a           -1.28712    8.67009  -0.148    0.882    \n#&gt; m            6.26459    0.60017  10.438   &lt;2e-16 ***\n#&gt; w1           0.61940    0.02087  29.675   &lt;2e-16 ***\n#&gt; a:m         -7.89838    5.28478  -1.495    0.135    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 42.17 on 12348 degrees of freedom\n#&gt; Multiple R-squared:  0.08882,    Adjusted R-squared:  0.08852 \n#&gt; F-statistic: 300.9 on 4 and 12348 DF,  p-value: &lt; 2.2e-16\n\n\nIn this model we can see:\n\nhigher red meat intake is associated with a lower blood glucose levels, independent of CRP\nthere is no statistically significant interaction between red meat and age. We still keep this in the model because even though the interaction is not statistically significant, it can still contribute to the outcomes. For an interaction to be statistically significant we often need a lot of power\nCRP is associated with higher blood glucose levels, independent of red meat intake\n\nBased on the coefficients of these two models, we can now estimate the different effects. The equations are from Valeri et al. [valeri2013] and VanderWeele et al. [vanderweele2014].\n\n6.2.1 Controlled direct effect\nThe controlled direct effect can be obtained using this formula based on the regression coefficients:\n\\(CDE(m) = (\\sigma_1 + \\sigma_3*m)(a - a^*)\\)\n\\(a^*\\) is for a change from level \\(a^*\\) (=control) to level \\(a\\) (=intervention).\nFor the controlled direct effect we set m to a specific value.\nLet’s look at the distribution of m.\n\nnhanes %&gt;% select(m) %&gt;% summary()\n\n#&gt;        m          \n#&gt;  Min.   :-4.6052  \n#&gt;  1st Qu.:-1.5606  \n#&gt;  Median :-1.5606  \n#&gt;  Mean   :-1.2888  \n#&gt;  3rd Qu.:-0.7765  \n#&gt;  Max.   : 2.9178\n\nmedian_m_log &lt;- round(median(nhanes$m), digits = 1)\n\nmedian_m &lt;- round(exp(median(nhanes$m)), digits = 1)\n\nIn this example we will set it to the median -1.6 which is a CRP at 0.2 which is a low level.\n\nCDE_m &lt;- (lm_y$coefficients[2] + lm_y$coefficients[5]*median_m_log)*(1 - 0) \n\nround(as.numeric(CDE_m), digits = 2)\n\n#&gt; [1] 11.35\n\n\nThe CDE is how much the outcome, here blood glucose, would change on average if the mediator, here inflammation measured by CRP levels, were fixed at level (m=0.2) uniformly in the population but the treatment, red meat intake, was changed from 0 to 65 g/day. As we operate with a linear model for simplicity, it does not matter here if the change is from 0 to 65 or from 50 to 115 g/day.\nThe CDE answer the question, what would be the effect of A on Y, when fixing M at a specific value for everyone in the population? [wang&arah2015]\n\n6.2.2 (Pure) natural direct effect\nPNDE can be obtained using this formula:\n\\(PNDE = (\\sigma_1 + \\sigma_3 * (\\beta_0 + beta_1*a^* + \\beta'_2*w))(a - a^*)\\)\nWe set the value for the confounder w1 for the interaction to be the mean value of w1.\n\nmean_w1 &lt;- mean(nhanes$w1)\n\nThen we calculate the PNDE.\n\nPNDE &lt;- (lm_y$coefficients[2] + (lm_y$coefficients[5]*(lm_m$coefficients[1] + lm_m$coefficients[2]*0 + lm_m$coefficients[3]*mean_w1)))*(1 - 0) \n\nround(as.numeric(PNDE), digits = 2)\n\n#&gt; [1] 8.63\n\n\nThe PNDE is how much the outcome, blood glucose, would change if the treatment a, red meat, was set at 65 versus 0 but for each individual the mediator was kept at the level it would have taken, for that individual, in the absence of the exposure.\nIn other words, to what extent does X cause Y via pathways other than through M [wang&arah2015].\n\n6.2.3 (Total) natural direct effect\nTNDE can be obtained by this formula:\n\\(TNDE = (\\sigma_1 + \\sigma_3 * (\\beta_0 + beta_1*a + \\beta'_2*w))(a - a^*)\\)\n\nTNDE &lt;- (lm_y$coefficients[2] + (lm_y$coefficients[5]*(lm_m$coefficients[1] + lm_m$coefficients[2]*1 + lm_m$coefficients[3]*mean_w1)))*(1 - 0) \n\nround(as.numeric(TNDE), digits = 2)\n\n#&gt; [1] 11.56\n\n\nHere, the value of M is enabled to act (as opposed to the PNDE). Here we see a little higher blood glucose, and that is the extra contribution from inflammation.\nThe TNDE asks the question: “to what extent does A cause Y via pathways other than through M, allowing M to boost up or tune down such effect at the same time?”\n\n6.2.4 Pure natural indirect effect\nThe PNIE can be obtained by this formula:\n\\(PNIE = (\\sigma_2 * \\beta_1 + \\sigma_3 * \\beta_1 * a^*)(a - a^*)\\)\n\nPNIE &lt;- ((lm_y$coefficients[3] * lm_m$coefficients[2]) + (lm_y$coefficients[5] * lm_m$coefficients[2] * 0))*(1 - 0) \n\nround(as.numeric(PNIE), digits = 2)\n\n#&gt; [1] -2.33\n\n\nThe PNIE is different from the TNIE because it does not include the interaction effect. We estimate the effect of red meat on inflammation and then subsequent effect of inflammation on blood glucose. As we saw above in the mediation model, red meat, lower inflammation. Hence, lowering inflammation lower blood glucose a little here.\nThe PNIE answer the question: “to what extent does A cause Y via M only (i.e., due to A affecting M and subsequently, M affecting Y), not accounting for the possible interaction between A and M? In other words, the effect that the exposure would have had if ‘its only action were to cause the mediator’ (i.e., the portion of the effect for which mediation is ‘‘sufficient’’)” [wang&arah2015].\n\n6.2.5 Total natural indirect effect\nThe TNIE can be obtained by this formula:\n\\(TNIE = (\\sigma_2 * \\beta_1 + \\sigma_3 * \\beta_1 * a)(a - a^*)\\)\n\nTNIE &lt;- ((lm_y$coefficients[3] * lm_m$coefficients[2]) + (lm_y$coefficients[5] * lm_m$coefficients[2] * 1))*(1 - 0) \n\nround(as.numeric(TNIE), digits = 2)\n\n#&gt; [1] 0.61\n\n\nThe TNIE is how much the outcome would change on average if the treatment were fixed at level a = 65 g/day but the mediator were changed from the level it would take if a* = 0 to the level it would take if a = 65 g/day.\nNote that exposure has to have an effect on M otherwise this will be zero.\nThe TNIE asks the question: to what extent does A cause Y via M (due to A affecting M and subsequently, M affecting Y) and the possible interaction between A and M in affecting Y? In other words, the effect of exposure that ‘would be prevented if the exposure did not cause the mediator’ (i.e., the portion of the effect for which mediation is ‘necessary’) [wang&arah2015].\nThis is often the effect we are interested in in biomedical research for questions regarding mediation.\n\n6.2.6 total effect\nThe total effect can be decomposed as:\n\\(TE = PNDE + TNIE\\)\n\nTE &lt;- PNDE + TNIE\n\nround(as.numeric(TE), digits = 2)\n\n#&gt; [1] 9.24\n\n\nThis is the overall effect of red meat on blood glucose levels. Higher red meat is associated with higher blood glucose.\n\n6.2.7 Proportion mediation\nFrom this, we can calculate the proportion mediated.\n\\(PM = \\frac{TNIE}{TE}\\)\n\nPM &lt;- TNIE / TE\n\nas.numeric(PM) * 100\n\n#&gt; [1] 6.569824\n\n\n6.6% of the association between red meat and blood glucose is mediated by M, inflammation. Not a lot.\n\n6.2.8 R package example for causal mediation analysis - CMAverse-package\nAll of this can be done using an R package. Here we can use several different approach for the estimation and get confidence intervals.\nFirst, we load the package and then we setup the model object. We have to specify:\n\nmodel: this is the type of model, or the approach for the causal mediation. We used the regression-based approach, so we will also do that here. However, one can also use weighting-based approach marginal structural models or the gformula.\noutcome: your outcome variable\nexposure: your exposure/intervention/treatment\nmediator: your mediator\nmreg: the type of model for the mediator. It is a list because you can have multiple mediators\nyreg: type of regression for the outcome. E.g., linear, logistic, cox.\nastar: Control/comparison intervention (value from)\na: Intervention (value to)\nmval: the value for the mediator when estimating the CDE\nEMin0t: indicator of whether there should be exposure and mediator interaction in the models.\nestimation: method for estimating causal effects. Can use parametric functions or imputation.\ninference: how to calculate confidence intervals. For regression-based we use the delta method. But for the other methods we use a bootstrap.\n\nIn short, all the things we did above can be estimated like this:\n\nlibrary(CMAverse)\n\nres_rb &lt;- cmest(data = nhanes, model = \"rb\", outcome = \"y\", exposure = \"a\",\n                            mediator = \"m\", basec = c(\"w1\"), EMint = TRUE,\n                            mreg = list(\"linear\"), yreg = \"linear\",\n                            astar = 0, a = 1, mval = list(-1.6), \n                            estimation = \"paramfunc\", inference = \"delta\")\n\nsummary(res_rb)\n\n#&gt; Causal Mediation Analysis\n#&gt; \n#&gt; # Outcome regression:\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = y ~ a + m + a * m + w1, family = gaussian(), data = getCall(x$reg.output$yreg)$data, \n#&gt;     weights = getCall(x$reg.output$yreg)$weights)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 87.55782    1.48088  59.126   &lt;2e-16 ***\n#&gt; a           -1.28712    8.67009  -0.148    0.882    \n#&gt; m            6.26459    0.60017  10.438   &lt;2e-16 ***\n#&gt; w1           0.61940    0.02087  29.675   &lt;2e-16 ***\n#&gt; a:m         -7.89838    5.28478  -1.495    0.135    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for gaussian family taken to be 1777.899)\n#&gt; \n#&gt;     Null deviance: 24093408  on 12352  degrees of freedom\n#&gt; Residual deviance: 21953492  on 12348  degrees of freedom\n#&gt; AIC: 127503\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 2\n#&gt; \n#&gt; \n#&gt; # Mediator regressions: \n#&gt; \n#&gt; Call:\n#&gt; glm(formula = m ~ a + w1, family = gaussian(), data = getCall(x$reg.output$mreg[[1L]])$data, \n#&gt;     weights = getCall(x$reg.output$mreg[[1L]])$weights)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -1.5171692  0.0280492 -54.090  &lt; 2e-16 ***\n#&gt; a           -0.3714291  0.1174787  -3.162  0.00157 ** \n#&gt; w1           0.0054803  0.0004741  11.559  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for gaussian family taken to be 0.9273031)\n#&gt; \n#&gt;     Null deviance: 11603  on 12352  degrees of freedom\n#&gt; Residual deviance: 11452  on 12350  degrees of freedom\n#&gt; AIC: 34129\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 2\n#&gt; \n#&gt; \n#&gt; # Effect decomposition on the mean difference scale via the regression-based approach\n#&gt;  \n#&gt; Closed-form parameter function estimation with \n#&gt;  delta method standard errors, confidence intervals and p-values \n#&gt;  \n#&gt;              Estimate Std.error  95% CIL 95% CIU   P.val    \n#&gt; cde          11.35029   5.35412  0.85642  21.844 0.03401 *  \n#&gt; pnde          8.62990   5.15858 -1.48073  18.741 0.09434 .  \n#&gt; tnde         11.56359   5.46142  0.85940  22.268 0.03423 *  \n#&gt; pnie         -2.32685   0.76898 -3.83402  -0.820 0.00248 ** \n#&gt; tnie          0.60684   1.81093 -2.94251   4.156 0.73755    \n#&gt; te            9.23674   5.34670 -1.24259  19.716 0.08407 .  \n#&gt; intref       -2.72039   1.82339 -6.29417   0.853 0.13571    \n#&gt; intmed        2.93369   2.17119 -1.32176   7.189 0.17663    \n#&gt; cde(prop)     1.22882   0.13374  0.96669   1.491 &lt; 2e-16 ***\n#&gt; intref(prop) -0.29452   0.22305 -0.73168   0.143 0.18669    \n#&gt; intmed(prop)  0.31761   0.25899 -0.18999   0.825 0.22006    \n#&gt; pnie(prop)   -0.25191   0.16211 -0.56964   0.066 0.12019    \n#&gt; pm            0.06570   0.18931 -0.30534   0.437 0.72856    \n#&gt; int           0.02309   0.09313 -0.15943   0.206 0.80416    \n#&gt; pe           -0.22882   0.13374 -0.49095   0.033 0.08709 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (cde: controlled direct effect; pnde: pure natural direct effect; tnde: total natural direct effect; pnie: pure natural indirect effect; tnie: total natural indirect effect; te: total effect; intref: reference interaction; intmed: mediated interaction; cde(prop): proportion cde; intref(prop): proportion intref; intmed(prop): proportion intmed; pnie(prop): proportion pnie; pm: overall proportion mediated; int: overall proportion attributable to interaction; pe: overall proportion eliminated)\n#&gt; \n#&gt; Relevant variable values: \n#&gt; $a\n#&gt; [1] 1\n#&gt; \n#&gt; $astar\n#&gt; [1] 0\n#&gt; \n#&gt; $mval\n#&gt; $mval[[1]]\n#&gt; [1] -1.6\n#&gt; \n#&gt; \n#&gt; $basecval\n#&gt; $basecval[[1]]\n#&gt; [1] 47.73326\n\n\nWe can check that the models were the ones we wanted to specify. And we can see that the results are the same.\nWe can now try to adjust for multiple other confounders.\n\nres_rb_confounders &lt;- cmest(data = nhanes, model = \"rb\", outcome = \"y\", exposure = \"a\",\n                            mediator = \"m\", basec = c(\"w1\", \"w2\", \"w3\"), EMint = TRUE,\n                            mreg = list(\"linear\"), yreg = \"linear\",\n                            astar = 0, a = 1, mval = list(-1.6), \n                            estimation = \"paramfunc\", inference = \"delta\")\n\nsummary(res_rb_confounders)\n\n#&gt; Causal Mediation Analysis\n#&gt; \n#&gt; # Outcome regression:\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = y ~ a + m + a * m + w1 + w2 + w3, family = gaussian(), \n#&gt;     data = getCall(x$reg.output$yreg)$data, weights = getCall(x$reg.output$yreg)$weights)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 95.42503    1.75206  54.464  &lt; 2e-16 ***\n#&gt; a           -6.98927    8.73758  -0.800    0.424    \n#&gt; m            5.99653    0.60146   9.970  &lt; 2e-16 ***\n#&gt; w1           0.58643    0.02104  27.869  &lt; 2e-16 ***\n#&gt; w2Male       3.45406    0.79579   4.340 1.43e-05 ***\n#&gt; w3          -2.66098    0.29522  -9.014  &lt; 2e-16 ***\n#&gt; a:m         -6.97911    5.26483  -1.326    0.185    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for gaussian family taken to be 1763.418)\n#&gt; \n#&gt;     Null deviance: 24093408  on 12352  degrees of freedom\n#&gt; Residual deviance: 21771153  on 12346  degrees of freedom\n#&gt; AIC: 127404\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 2\n#&gt; \n#&gt; \n#&gt; # Mediator regressions: \n#&gt; \n#&gt; Call:\n#&gt; glm(formula = m ~ a + w1 + w2 + w3, family = gaussian(), data = getCall(x$reg.output$mreg[[1L]])$data, \n#&gt;     weights = getCall(x$reg.output$mreg[[1L]])$weights)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -1.1425719  0.0359606  -31.77   &lt;2e-16 ***\n#&gt; a            0.1457568  0.1204462    1.21    0.226    \n#&gt; w1           0.0050725  0.0004724   10.74   &lt;2e-16 ***\n#&gt; w2Male      -0.2748443  0.0177739  -15.46   &lt;2e-16 ***\n#&gt; w3          -0.0903754  0.0066090  -13.68   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for gaussian family taken to be 0.8972118)\n#&gt; \n#&gt;     Null deviance: 11603  on 12352  degrees of freedom\n#&gt; Residual deviance: 11079  on 12348  degrees of freedom\n#&gt; AIC: 33723\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 2\n#&gt; \n#&gt; \n#&gt; # Effect decomposition on the mean difference scale via the regression-based approach\n#&gt;  \n#&gt; Closed-form parameter function estimation with \n#&gt;  delta method standard errors, confidence intervals and p-values \n#&gt;  \n#&gt;               Estimate Std.error   95% CIL 95% CIU P.val\n#&gt; cde            4.17731   5.54891  -6.69835  15.053 0.452\n#&gt; pnde           2.09686   5.34131  -8.37192  12.566 0.695\n#&gt; tnde           1.07960   5.45829  -9.61846  11.778 0.843\n#&gt; pnie           0.87403   0.72756  -0.55196   2.300 0.230\n#&gt; tnie          -0.14322   0.71406  -1.54275   1.256 0.841\n#&gt; te             1.95364   5.39456  -8.61951  12.527 0.717\n#&gt; intref        -2.08045   1.57236  -5.16222   1.001 0.186\n#&gt; intmed        -1.01725   1.13820  -3.24808   1.214 0.371\n#&gt; cde(prop)      2.13822   3.50275  -4.72704   9.003 0.542\n#&gt; intref(prop)  -1.06491   3.15645  -7.25143   5.122 0.736\n#&gt; intmed(prop)  -0.52070   1.60511  -3.66666   2.625 0.746\n#&gt; pnie(prop)     0.44739   1.29763  -2.09593   2.991 0.730\n#&gt; pm            -0.07331   0.44198  -0.93957   0.793 0.868\n#&gt; int           -1.58561   4.71882 -10.83432   7.663 0.737\n#&gt; pe            -1.13822   3.50275  -8.00348   5.727 0.745\n#&gt; \n#&gt; (cde: controlled direct effect; pnde: pure natural direct effect; tnde: total natural direct effect; pnie: pure natural indirect effect; tnie: total natural indirect effect; te: total effect; intref: reference interaction; intmed: mediated interaction; cde(prop): proportion cde; intref(prop): proportion intref; intmed(prop): proportion intmed; pnie(prop): proportion pnie; pm: overall proportion mediated; int: overall proportion attributable to interaction; pe: overall proportion eliminated)\n#&gt; \n#&gt; Relevant variable values: \n#&gt; $a\n#&gt; [1] 1\n#&gt; \n#&gt; $astar\n#&gt; [1] 0\n#&gt; \n#&gt; $mval\n#&gt; $mval[[1]]\n#&gt; [1] -1.6\n#&gt; \n#&gt; \n#&gt; $basecval\n#&gt; $basecval[[1]]\n#&gt; [1] 47.73326\n#&gt; \n#&gt; $basecval[[2]]\n#&gt; [1] 0.502469\n#&gt; \n#&gt; $basecval[[3]]\n#&gt; [1] 2.914029\n\n\nAfter adjustment for age, sex and education, there is not longer statistically significant associations."
  },
  {
    "objectID": "sessions/causal-mediation-analysis-estimation.html#g-computation-based-approach",
    "href": "sessions/causal-mediation-analysis-estimation.html#g-computation-based-approach",
    "title": "\n6  Estimation of effects using causal mediation analysis\n",
    "section": "\n6.3 G-computation-based approach",
    "text": "6.3 G-computation-based approach\nUnder the above mentioned assumptions, we can also calculate the estimate using the G-computation approach.\nThe approach here is more manual but we also have more flexibility in the models with use.\nWe will test this out using the Framgingham dataset. Our research question is:\n\nDoes obesity lead to higher CVD risk by increasing blood pressure?\n\nWe load the data, rename the variables, make a few categorical variables and only keep the variables we need.\n\nframingham &lt;- read.csv(here::here(\"data\", \"frmgham2.csv\"))\n\nframingham &lt;- framingham %&gt;% select(id = RANDID,\n                                     BMI,\n                                     SYSBP,\n                                     y = CVD,\n                                     w1 = SEX,\n                                     w2 = CURSMOKE,\n                                     w3 = AGE) %&gt;% \n  na.omit() %&gt;% \n  mutate(a = case_when(BMI &gt;= 25 ~ 1,\n                       TRUE ~ 0),\n         m = case_when(SYSBP &gt;= 140 ~ 1,\n                       TRUE ~ 0)) %&gt;% \n  select(-BMI, -SYSBP)\n\nFirst, we fit the outcome regression (including interaction terms).\n\nor_fit &lt;- glm(y ~ a + m + w1 + w2 + a*m + m*w1 + w3,\n              family = binomial(), data = framingham)\nsummary(or_fit)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = y ~ a + m + w1 + w2 + a * m + m * w1 + w3, family = binomial(), \n#&gt;     data = framingham)\n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -2.924761   0.192566 -15.188  &lt; 2e-16 ***\n#&gt; a            0.236296   0.065230   3.623 0.000292 ***\n#&gt; m            0.283291   0.161669   1.752 0.079724 .  \n#&gt; w1          -0.991441   0.066757 -14.851  &lt; 2e-16 ***\n#&gt; w2           0.357061   0.048958   7.293 3.03e-13 ***\n#&gt; w3           0.048250   0.002664  18.109  &lt; 2e-16 ***\n#&gt; a:m          0.064286   0.095193   0.675 0.499475    \n#&gt; m:w1         0.262132   0.093541   2.802 0.005074 ** \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 12986  on 11574  degrees of freedom\n#&gt; Residual deviance: 11761  on 11567  degrees of freedom\n#&gt; AIC: 11777\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\nBased on the outcome regression model, we can predict Y under different scenarios. We first make a function that predict the outcome with different inputs for A and M. Then we use the function to predict the out with different combinations of A and M.\n\nget_EY_a_m_Wi &lt;- function(full_data, or_fit, A, M){\n  data_Aa_Mm_Wi &lt;- full_data\n  data_Aa_Mm_Wi$a &lt;- A; data_Aa_Mm_Wi$m &lt;- M\n  predict(or_fit, newdata = data_Aa_Mm_Wi, type = \"response\")\n}\n## run prediction, for different scenarios (a=1 or 0, and m=1 or 0)\nEY_A0_M0_Wi &lt;- get_EY_a_m_Wi(framingham, or_fit, A = 0, M = 0)\nEY_A0_M1_Wi &lt;- get_EY_a_m_Wi(framingham, or_fit, A = 0, M = 1)\nEY_A1_M0_Wi &lt;- get_EY_a_m_Wi(framingham, or_fit, A = 1, M = 0)\nEY_A1_M1_Wi &lt;- get_EY_a_m_Wi(framingham, or_fit, A = 1, M = 1)\n\nNext, we will run the mediation model. Also including interaction terms.\n\nmed_fit &lt;- glm(m ~ a*w1 + w1*w2, family = binomial(), data = framingham)\n\nWe now make a new function that based on the values of A, run the prediction models of M. This is the nested counterfactual.\n\n# estimates of Pr(M = m | A = a, W = W_i), predict m based on a\nget_Pm_a_Wi &lt;- function(full_data, med_fit, A, M){\n  data_Aa_Wi &lt;- full_data; data_Aa_Wi$a &lt;- A\n  p &lt;- predict(med_fit, newdata = data_Aa_Wi, type = \"response\")\n  if(M == 1){\n    p\n  }else{\n    1 - p\n  }\n}\n##similary, we get the predicted values of m for different scenarios\nPM0_A0_Wi &lt;- get_Pm_a_Wi(framingham, med_fit, A = 0, M = 0)\nPM1_A0_Wi &lt;- get_Pm_a_Wi(framingham, med_fit, A = 0, M = 1)\nPM0_A1_Wi &lt;- get_Pm_a_Wi(framingham, med_fit, A = 1, M = 0)\nPM1_A1_Wi &lt;- get_Pm_a_Wi(framingham, med_fit, A = 1, M = 1)\n\nFinally, we calculate the predicted Y on the estimates.\n\n# E(E(Y | A = 1, M, W) | A = 1, W)\nEY1M1_Wi &lt;- EY_A1_M1_Wi * PM1_A1_Wi + EY_A1_M0_Wi * PM0_A1_Wi\n# E(E(Y | A = 0, M, W) | A = 1, W)\nEY0M1_Wi &lt;- EY_A0_M1_Wi * PM1_A1_Wi + EY_A0_M0_Wi * PM0_A1_Wi\n# E(E(Y | A = 1, M, W) | A = 0, W)\nEY1M0_Wi &lt;- EY_A1_M1_Wi * PM1_A0_Wi + EY_A1_M0_Wi * PM0_A0_Wi\n# E(E(Y | A = 0, M, W) | A = 0, W)\nEY0M0_Wi &lt;- EY_A0_M1_Wi * PM1_A0_Wi + EY_A0_M0_Wi * PM0_A0_Wi\n\n#Finally, we average over distribution of W to get effect estimate \n# estimate of E[Y(1, M(1))]\nE_Y1M1 &lt;- mean(EY1M1_Wi)\n# estimate of E[Y(0, M(1))]\nE_Y0M1 &lt;- mean(EY0M1_Wi)\n# estimate of E[Y(1, M(0))]\nE_Y1M0 &lt;- mean(EY1M0_Wi)\n# estimate of E[Y(0, M(0))]\nE_Y0M0 &lt;- mean(EY0M0_Wi)\n\nNow, you can freely calculate the natural direct effect and indirect effect:\n\n#changing the intervention, keeping the mediator the same\nPNDE_gcomp = round(exp(E_Y1M0 - E_Y0M0), digits = 2)\n\nTNDE_gcomp = round(exp(E_Y1M1 - E_Y0M1), digits = 2)\n\n#change the mediator keeping intervention the same\nPNIE_comp = round(exp(E_Y0M1 - E_Y0M0), digits = 2)\n\nTNIE_comp = round(exp(E_Y1M1 - E_Y1M0), digits = 2) \n\nest_table &lt;- data.frame(PNDE = PNDE_gcomp,\n                        TNDE = TNDE_gcomp,\n                        PNIE = PNIE_comp,\n                        TNIE = TNIE_comp)\nest_table\n\n#&gt; # A tibble: 1 × 4\n#&gt;    PNDE  TNDE  PNIE  TNIE\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  1.04  1.05  1.02  1.02"
  }
]